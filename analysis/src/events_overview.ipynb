{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50a68c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.cm as cm\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib_venn import venn3\n",
    "from itertools import combinations\n",
    "import matplotlib.ticker as mticker\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9eddcb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = int(os.getenv(\"DB_PORT\"))\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac2873ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrotr = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    dbname=DB_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703dd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate events.csv if it does not exist\n",
    "if \"events.csv\" not in os.listdir(DATA_FOLDER):\n",
    "    with bigbrotr.cursor() as cur:\n",
    "        with open(os.path.join(DATA_FOLDER, 'events.csv'), 'w') as f:\n",
    "            cur.copy_expert(\"COPY (SELECT id, pubkey, created_at, kind FROM events) TO STDOUT WITH CSV HEADER\", f)\n",
    "# Load events data\n",
    "events = pl.read_csv(os.path.join(DATA_FOLDER, 'events.csv'), columns=[\"pubkey\", \"created_at\", \"kind\"])\n",
    "events = events.with_columns(\n",
    "    (pl.col(\"created_at\") * 1000).cast(pl.Datetime(\"ms\")).alias(\"created_at\")\n",
    ")\n",
    "events = events.with_columns([\n",
    "    pl.col(\"created_at\").dt.truncate(\"1d\").alias(\"day\"),\n",
    "    pl.col(\"created_at\").dt.truncate(\"1mo\").alias(\"month\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ceba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total events and unique pubkeys\n",
    "total_events = events.shape[0]\n",
    "total_pubkeys = events['pubkey'].n_unique()\n",
    "print(f\"Number of total events: {total_events}\")\n",
    "print(f\"Number of unique pubkeys: {total_pubkeys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count events grouped by their 'kind' value\n",
    "kind_counts = (\n",
    "    events.group_by(\"kind\")             # Group the DataFrame by the 'kind' column\n",
    "    .agg(pl.count())                    # Aggregate each group by counting the number of rows (events)\n",
    "    .rename({\"count\": \"count\"})        # Rename the resulting count column to 'count' (optional here, since default is 'count')\n",
    "    .sort(\"count\", descending=True)   # Sort the groups by count in descending order (most frequent kinds first)\n",
    "    .with_columns(                     # Add a new column calculating the percentage of each kind's count relative to total\n",
    "        (pl.col(\"count\") / pl.col(\"count\").sum() * 100).alias(\"perc\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Top 20 event kinds by count:\")\n",
    "kind_counts.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b779006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the top 20 rows of kind_counts (Polars DF) to Pandas for plotting\n",
    "df_plot = kind_counts.head(20).to_pandas()\n",
    "\n",
    "# Convert 'kind' to string for categorical x-axis labels\n",
    "kind_labels = df_plot['kind'].astype(str)\n",
    "\n",
    "# Setup figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Colors for bar and line\n",
    "color_count = '#4C72B0'  # soft blue\n",
    "color_perc = '#DD8452'   # orange\n",
    "\n",
    "# Primary axis grid only on y-axis (vertical grid lines off)\n",
    "ax1.grid(axis='y', linestyle='--', color=color_count, alpha=0.5, zorder=0)\n",
    "ax1.grid(axis='x', visible=False)\n",
    "\n",
    "# Bar plot for counts with log scale on y-axis\n",
    "ax1.bar(kind_labels, df_plot['count'], color=color_count, edgecolor='black', label='Number of Events', zorder=1)\n",
    "ax1.set_xlabel('Kind')\n",
    "ax1.set_ylabel('Number of Events (log scale)', color=color_count)\n",
    "ax1.set_yscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor=color_count)\n",
    "\n",
    "# Secondary axis for percentage line plot\n",
    "ax2 = ax1.twinx()\n",
    "ax2.patch.set_visible(False)  # Transparent background\n",
    "\n",
    "# Line plot for percentages\n",
    "ax2.plot(kind_labels, df_plot['perc'], color=color_perc, marker='o', label='Percentage of Events (%)', zorder=3)\n",
    "ax2.set_ylabel('Percentage of Events (%)', color=color_perc)\n",
    "ax2.tick_params(axis='y', labelcolor=color_perc)\n",
    "\n",
    "# Grid for secondary axis on y only\n",
    "ax2.grid(axis='y', linestyle='--', color=color_perc, alpha=0.5, zorder=0)\n",
    "\n",
    "# Title and combined legend from both axes\n",
    "fig.suptitle('Event Kind Distribution')\n",
    "\n",
    "lines_labels = ax1.get_legend_handles_labels()[0] + ax2.get_legend_handles_labels()[0]\n",
    "labels = ax1.get_legend_handles_labels()[1] + ax2.get_legend_handles_labels()[1]\n",
    "fig.legend(lines_labels, labels)\n",
    "\n",
    "# Layout and spacing adjustments\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select unique pairs of ('kind', 'pubkey') to get unique users per event kind\n",
    "kind_share = events.unique(subset=[\"kind\", \"pubkey\"])\n",
    "\n",
    "# Count how many unique users ('pubkey') exist for each 'kind'\n",
    "kind_share = (\n",
    "    kind_share.group_by(\"kind\")\n",
    "    .agg(pl.count(\"pubkey\").alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the percentage share of each kind relative to total unique users\n",
    "kind_share = kind_share.with_columns(\n",
    "    (pl.col(\"count\") / pl.col(\"count\").sum() * 100).alias(\"perc\")\n",
    ")\n",
    "\n",
    "print(\"Top 20 event kinds by unique users:\")\n",
    "kind_share.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert top 20 rows of kind_share (Polars DataFrame) to Pandas for plotting\n",
    "df_plot = kind_share.head(20).to_pandas()\n",
    "\n",
    "# Convert 'kind' to string for categorical x-axis labels\n",
    "kind_labels = df_plot['kind'].astype(str)\n",
    "\n",
    "# Set up the figure and primary axis\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Colors for bars and line\n",
    "color_count = '#4C72B0'  # soft blue\n",
    "color_perc = '#DD8452'   # orange\n",
    "\n",
    "# Primary axis grid on y only, no x grid\n",
    "ax1.grid(axis='y', linestyle='--', color=color_count, alpha=0.5, zorder=0)\n",
    "ax1.grid(axis='x', visible=False)\n",
    "\n",
    "# Bar chart for number of unique pubkeys, y-axis log scale\n",
    "ax1.bar(kind_labels, df_plot['count'], color=color_count, edgecolor='black',\n",
    "        label='Number of Pubkeys', zorder=1)\n",
    "ax1.set_xlabel('Kind')\n",
    "ax1.set_ylabel('Number of Pubkeys (log scale)', color=color_count)\n",
    "ax1.set_yscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor=color_count)\n",
    "\n",
    "# Secondary axis for percentage line plot\n",
    "ax2 = ax1.twinx()\n",
    "ax2.patch.set_visible(False)  # Transparent background\n",
    "\n",
    "# Line plot for percentage of pubkeys\n",
    "ax2.plot(kind_labels, df_plot['perc'], color=color_perc, marker='o',\n",
    "         label='Percentage of Pubkeys (%)', zorder=3)\n",
    "ax2.set_ylabel('Percentage of Pubkeys (%)', color=color_perc)\n",
    "ax2.tick_params(axis='y', labelcolor=color_perc)\n",
    "\n",
    "# Grid on secondary y-axis only\n",
    "ax2.grid(axis='y', linestyle='--', color=color_perc, alpha=0.5, zorder=0)\n",
    "\n",
    "# Title and combined legend\n",
    "fig.suptitle('Event Kind Used by Pubkeys')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines_labels = ax1.get_legend_handles_labels()[0] + ax2.get_legend_handles_labels()[0]\n",
    "labels = ax1.get_legend_handles_labels()[1] + ax2.get_legend_handles_labels()[1]\n",
    "fig.legend(lines_labels, labels)\n",
    "\n",
    "# Final layout adjustment\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'kind_share' and 'kind_counts' on 'kind' column\n",
    "kind_stats = kind_share.join(\n",
    "    kind_counts,\n",
    "    on=\"kind\",\n",
    "    how=\"inner\",\n",
    "    suffix=\"_pubkey\"\n",
    ").rename({\n",
    "    col: col + \"_event\" for col in kind_counts.columns if col != \"kind\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422bf1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Polars DataFrame to Pandas for plotting\n",
    "kind_stats_pd = kind_stats.to_pandas()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Scatter plot: pubkey percentage vs event percentage by kind (axes swapped)\n",
    "sns.scatterplot(\n",
    "    data=kind_stats_pd,\n",
    "    x='perc_pubkey',  # x is now pubkey percentage\n",
    "    y='perc_event',   # y is now event percentage\n",
    ")\n",
    "\n",
    "plt.xlabel('Pubkey Percentage')   # swapped labels\n",
    "plt.ylabel('Event Percentage')\n",
    "plt.title('Pubkey vs Event Percentage by Kind')\n",
    "\n",
    "# Use symmetric log scale for both axes\n",
    "plt.xscale('symlog')\n",
    "plt.yscale('symlog')\n",
    "\n",
    "# Determine min and max values from both percentages for consistent axis limits\n",
    "min_val = min(kind_stats_pd['perc_event'].min(), kind_stats_pd['perc_pubkey'].min())\n",
    "max_val = max(kind_stats_pd['perc_event'].max(), kind_stats_pd['perc_pubkey'].max())\n",
    "\n",
    "plt.xlim(min_val - 0.5, max_val + 10)\n",
    "plt.ylim(min_val - 0.5, max_val + 10)\n",
    "\n",
    "# Add labels for points where either percentage >= 0.5% (swap x and y here too)\n",
    "for i, row in kind_stats_pd.iterrows():\n",
    "    if row['perc_event'] >= 0.5 or row['perc_pubkey'] >= 0.5:\n",
    "        kind_value = int(row['kind'])  # cast to int here\n",
    "        x_val = row['perc_pubkey']\n",
    "        y_val = row['perc_event']\n",
    "\n",
    "        if kind_value in [321, 6300, 31234]:\n",
    "            plt.text(x_val, y_val, kind_value, ha='center', va='baseline', rotation=-45)\n",
    "        elif kind_value == 5300:\n",
    "            plt.text(x_val, y_val, kind_value, ha='left', va='top', rotation=-45)\n",
    "        elif kind_value not in [3, 1000]:\n",
    "            plt.text(x_val, y_val, kind_value, ha='left', va='baseline')\n",
    "        else:  # kind_value in [3, 1000]\n",
    "            plt.text(x_val, y_val, kind_value, ha='right', va='baseline')\n",
    "\n",
    "# Add threshold lines at 1% (horizontal and vertical swapped)\n",
    "plt.axvline(x=1, linestyle='--', color='red', label='1% Threshold')\n",
    "plt.axhline(y=1, linestyle='--', color='red')\n",
    "\n",
    "# Add diagonal line (x=y)\n",
    "plt.plot([min_val - 0.5, max_val + 10], [min_val - 0.5, max_val + 10],\n",
    "         linestyle='--', color='gray', label='Diagonal')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load additional metadata about kinds from CSV\n",
    "kinds_info = pd.read_csv(os.path.join(DATA_FOLDER, 'kinds_info.csv'))\n",
    "\n",
    "# Filter kinds where either event or pubkey percentage >= 0.5%\n",
    "relevant_kinds = kind_stats_pd[\n",
    "    (kind_stats_pd['perc_event'] >= 0.5) | (kind_stats_pd['perc_pubkey'] >= 0.5)\n",
    "][['kind']]\n",
    "\n",
    "# Merge filtered kinds with metadata\n",
    "relevant_kinds = relevant_kinds.merge(kinds_info, on='kind', how='left')\n",
    "\n",
    "# Show resulting DataFrame\n",
    "display(relevant_kinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58966948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubkey_stats = (\n",
    "    events\n",
    "    .sort([\"pubkey\", \"created_at\"])\n",
    "    .group_by(\"pubkey\")\n",
    "    .agg([\n",
    "        pl.count().alias(\"event_count\"),\n",
    "        pl.min(\"created_at\").alias(\"first_eventdate\"),\n",
    "        pl.max(\"created_at\").alias(\"last_eventdate\"),\n",
    "        pl.col(\"created_at\").diff().alias(\"intervals\")\n",
    "    ])\n",
    "    .explode(\"intervals\")\n",
    "    .group_by(\"pubkey\")\n",
    "    .agg([\n",
    "        pl.first(\"event_count\"),\n",
    "        pl.first(\"first_eventdate\"),\n",
    "        pl.first(\"last_eventdate\"),\n",
    "        (pl.first(\"last_eventdate\") - pl.first(\"first_eventdate\")).alias(\"lifespan\"),\n",
    "        pl.mean(\"intervals\").alias(\"mean_interval\"),\n",
    "        pl.median(\"intervals\").alias(\"median_interval\"),\n",
    "        pl.std(\"intervals\").alias(\"std_interval\")\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the number of events per pubkey from pubkey_stats\n",
    "freq = pubkey_stats[\"event_count\"].to_list()\n",
    "freq_sorted = np.sort(freq)\n",
    "\n",
    "# Step 2: Compute the cumulative distribution function (CDF)\n",
    "cdf = np.arange(1, len(freq_sorted) + 1) / len(freq_sorted)\n",
    "\n",
    "# Step 3: Main plot - CDF of event frequency per pubkey\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.step(freq_sorted, cdf, where='post', label='CDF of event frequency per pubkey')\n",
    "ax.set_xlabel('Number of events per pubkey')\n",
    "ax.set_ylabel('Cumulative percentage of pubkeys')\n",
    "ax.set_title('CDF of Event Frequency per Pubkey')\n",
    "ax.set_xscale('log')  # Logarithmic x-axis to better show long tail\n",
    "ax.grid(True)\n",
    "\n",
    "# Step 4: Zoom in on the top 10% of the distribution\n",
    "mask = cdf >= 0.9\n",
    "freq_zoom = freq_sorted[mask]\n",
    "cdf_zoom = cdf[mask]\n",
    "\n",
    "# Step 5: Inset plot - Focus on top 10% of pubkeys\n",
    "ax_inset = inset_axes(\n",
    "    ax,\n",
    "    width=\"40%\",\n",
    "    height=\"40%\",\n",
    "    loc='lower center',\n",
    "    bbox_to_anchor=(0.05, 0.15, 1, 1),\n",
    "    bbox_transform=ax.transAxes\n",
    ")\n",
    "ax_inset.step(freq_zoom, cdf_zoom, where='post')\n",
    "ax_inset.set_xscale('log')\n",
    "ax_inset.set_ylim(0.9, 1.001)\n",
    "ax_inset.set_title('Zoom: Top 10%', fontsize=10)\n",
    "ax_inset.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 1: Pubkeys that appear only once ---\n",
    "\n",
    "# Filter pubkeys with only one event from pubkey_stats\n",
    "single_use_pubkeys = pubkey_stats.filter(\n",
    "    pl.col(\"event_count\") == 1\n",
    ").select(\"pubkey\")\n",
    "\n",
    "# Keep only events from those pubkeys\n",
    "events_single_use = events.join(single_use_pubkeys, on=\"pubkey\", how=\"inner\")\n",
    "\n",
    "# Group by 'kind' and count events\n",
    "kind_stats_single_use = (\n",
    "    events_single_use\n",
    "    .group_by(\"kind\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate percentage per kind\n",
    "total_single_use = kind_stats_single_use[\"count\"].sum()\n",
    "kind_stats_single_use = kind_stats_single_use.with_columns([\n",
    "    (pl.col(\"count\") / total_single_use * 100).alias(\"percentage\")\n",
    "])\n",
    "\n",
    "print(\"Event kind statistics for pubkeys used only once:\")\n",
    "display(kind_stats_single_use.head(10))\n",
    "\n",
    "\n",
    "# --- Part 2: Top 1% most active pubkeys ---\n",
    "\n",
    "# Calculate number of pubkeys in the top 1%\n",
    "top_1_count = int(0.01 * pubkey_stats.height)\n",
    "\n",
    "# Get the top 1% by num_events\n",
    "top_1_percent_pubkeys = (\n",
    "    pubkey_stats\n",
    "    .sort(\"event_count\", descending=True)\n",
    "    .head(top_1_count)\n",
    "    .select(\"pubkey\")\n",
    ")\n",
    "\n",
    "# Keep only events from those pubkeys\n",
    "events_top_1 = events.join(top_1_percent_pubkeys, on=\"pubkey\", how=\"inner\")\n",
    "\n",
    "# Group by 'kind' and count events\n",
    "kind_stats_top_1 = (\n",
    "    events_top_1\n",
    "    .group_by(\"kind\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate percentage per kind\n",
    "total_top_1 = kind_stats_top_1[\"count\"].sum()\n",
    "kind_stats_top_1 = kind_stats_top_1.with_columns([\n",
    "    (pl.col(\"count\") / total_top_1 * 100).alias(\"percentage\")\n",
    "])\n",
    "\n",
    "print(\"Event kind statistics for the top 1% most active pubkeys:\")\n",
    "display(kind_stats_top_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter events by selected kinds from relevant_kinds dataframe\n",
    "events_filtered = events.filter(pl.col(\"kind\").is_in(relevant_kinds[\"kind\"].to_list()))\n",
    "\n",
    "# Count number of events per (pubkey, kind) pair\n",
    "pubkey_kind_counts = (\n",
    "    events_filtered\n",
    "    .group_by([\"pubkey\", \"kind\"])\n",
    "    .agg(pl.count().alias(\"num_events\"))\n",
    ")\n",
    "\n",
    "# Define 'up_kinds' and 'down_kinds' based on percentage comparisons and threshold\n",
    "up_kinds = kind_stats.filter(\n",
    "    (pl.col(\"perc_event\") < pl.col(\"perc_pubkey\")) &\n",
    "    ((pl.col(\"perc_event\") >= 1) | (pl.col(\"perc_pubkey\") >= 1))\n",
    ").select(\"kind\").to_series().to_list()\n",
    "\n",
    "down_kinds = kind_stats.filter(\n",
    "    (pl.col(\"perc_event\") >= pl.col(\"perc_pubkey\")) &\n",
    "    ((pl.col(\"perc_event\") >= 1) | (pl.col(\"perc_pubkey\") >= 1))\n",
    ").select(\"kind\").to_series().to_list()\n",
    "\n",
    "# Create two vertically stacked subplots with shared x-axis\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "for ax, kinds, title in zip(axes, [up_kinds, down_kinds], ['Up Kinds', 'Down Kinds']):\n",
    "    # Create inset axis for zoomed-in CDF of last 10%\n",
    "    ax_inset = inset_axes(\n",
    "        ax, width=\"40%\", height=\"40%\", loc='lower center',\n",
    "        bbox_to_anchor=(0.05, 0.15, 1, 1), bbox_transform=ax.transAxes\n",
    "    )\n",
    "\n",
    "    for kind in kinds:\n",
    "        counts = pubkey_kind_counts.filter(pl.col(\"kind\") == kind)[\"num_events\"].to_list()\n",
    "        if not counts:\n",
    "            continue\n",
    "\n",
    "        sorted_counts = np.sort(counts)\n",
    "        cdf = np.arange(1, len(sorted_counts) + 1) / len(sorted_counts)\n",
    "\n",
    "        # Plot full CDF on main axis\n",
    "        ax.step(sorted_counts, cdf, where='post', label=f\"kind {kind}\")\n",
    "\n",
    "        # Plot zoomed-in CDF (top 5%) on inset axis\n",
    "        mask = cdf >= 0.95\n",
    "        ax_inset.step(sorted_counts[mask], cdf[mask], where='post')\n",
    "\n",
    "    # Main axis formatting\n",
    "    ax.set_ylabel(\"Cumulative percentage of pubkeys\")\n",
    "    ax.set_title(f\"CDF of event frequencies per pubkey for selected kinds - {title}\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Inset axis formatting\n",
    "    ax_inset.set_xscale('log')\n",
    "    ax_inset.set_ylim(0.95)\n",
    "    ax_inset.set_title(\"Zoom last 5%\", fontsize=10)\n",
    "    ax_inset.grid(True)\n",
    "\n",
    "# Shared x-axis formatting\n",
    "axes[-1].set_xlabel(\"Number of events per pubkey\")\n",
    "axes[-1].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd48f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_set_intersections(sets):\n",
    "    \"\"\"\n",
    "    Compute intersections of all combinations of given sets and return a DataFrame\n",
    "    with counts and percentages relative to the total unique elements across all sets.\n",
    "\n",
    "    Parameters:\n",
    "    - sets: dict[str, set]\n",
    "        A dictionary where keys are set labels and values are sets of pubkeys (or elements).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame with columns:\n",
    "        'kind_combination' : str (comma-separated combination of set keys)\n",
    "        'count'            : int (number of elements in the intersection)\n",
    "        'perc'             : float (percentage of intersection relative to total unique elements)\n",
    "    \"\"\"\n",
    "    all_keys = list(sets.keys())\n",
    "    # Calculate total number of unique pubkeys across all sets (union)\n",
    "    total_pubkeys = len(set.union(*sets.values()))\n",
    "\n",
    "    intersections = {}\n",
    "\n",
    "    # Iterate over all possible combinations of keys (from size 1 up to all keys)\n",
    "    for r in range(1, len(all_keys) + 1):\n",
    "        for combo in combinations(all_keys, r):\n",
    "            # Compute intersection of sets for current combination of keys\n",
    "            intersect = set.intersection(*[sets[k] for k in combo])\n",
    "            count = len(intersect)\n",
    "            perc = (count / total_pubkeys * 100) if total_pubkeys > 0 else 0\n",
    "            intersections[combo] = {\"count\": count, \"perc\": perc}\n",
    "\n",
    "    # Convert intersection data into a list of dicts for DataFrame creation\n",
    "    rows = [\n",
    "        {\n",
    "            \"kind_combination\": \", \".join(combo),\n",
    "            \"count\": stats[\"count\"],\n",
    "            \"perc\": stats[\"perc\"]\n",
    "        }\n",
    "        for combo, stats in intersections.items()\n",
    "    ]\n",
    "\n",
    "    # Create DataFrame and sort by count descending\n",
    "    intersections_df = pd.DataFrame(rows).sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return intersections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Create sets of pubkeys for each event kind group ---\n",
    "\n",
    "# Extract unique pubkeys for kind 0 events\n",
    "kind_0 = set(\n",
    "    events.filter(pl.col(\"kind\") == 0)\n",
    "    .select(\"pubkey\")\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "# Extract unique pubkeys for kind 3 events\n",
    "kind_3 = set(\n",
    "    events.filter(pl.col(\"kind\") == 3)\n",
    "    .select(\"pubkey\")\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "# Extract unique pubkeys for kinds 1, 6, and 7 combined\n",
    "kind_1_6_7 = set(\n",
    "    events.filter(pl.col(\"kind\").is_in([1, 6, 7]))\n",
    "    .select(\"pubkey\")\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "# Combine sets into a dictionary for processing and plotting\n",
    "kind_sets = {\n",
    "    \"kind_0\": kind_0,\n",
    "    \"kind_3\": kind_3,\n",
    "    \"kind_1_6_7\": kind_1_6_7\n",
    "}\n",
    "\n",
    "# Calculate total number of unique pubkeys in the entire dataset\n",
    "all_pubkeys_count = events.select(pl.col(\"pubkey\").n_unique()).to_series().item()\n",
    "\n",
    "# Calculate unique pubkeys among selected kinds 0, 3, 1, 6, 7\n",
    "all_kind_pubkeys_count = events.filter(\n",
    "    pl.col(\"kind\").is_in([0, 3, 1, 6, 7])\n",
    ").select(pl.col(\"pubkey\").n_unique()).to_series().item()\n",
    "\n",
    "print(f\"Total unique pubkeys: {all_pubkeys_count}\")\n",
    "print(f\"Unique pubkeys in kinds 0, 3, 1, 6, 7: {all_kind_pubkeys_count} \"\n",
    "      f\"({all_kind_pubkeys_count / all_pubkeys_count * 100:.2f}%)\")\n",
    "\n",
    "# --- Step 2: Plot proportional Venn diagram for the three sets ---\n",
    "\n",
    "# Since there are 3 sets, use venn3 which supports proportional sizing\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "venn3(subsets=kind_sets.values(), set_labels=kind_sets.keys())\n",
    "\n",
    "plt.title(\"Proportional Venn Diagram of Pubkeys by Event Kind (0, 3, 1_6_7)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Step 3: Compute and display intersections statistics ---\n",
    "\n",
    "intersections_df = compute_set_intersections(kind_sets)\n",
    "print(intersections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Create sets of unique pubkeys for kinds 1, 6, and 7 ---\n",
    "\n",
    "kind_1 = set(events.filter(pl.col(\"kind\") == 1).select(\"pubkey\").to_series().to_list())\n",
    "kind_6 = set(events.filter(pl.col(\"kind\") == 6).select(\"pubkey\").to_series().to_list())\n",
    "kind_7 = set(events.filter(pl.col(\"kind\") == 7).select(\"pubkey\").to_series().to_list())\n",
    "\n",
    "# Dictionary of the pubkey sets by kind\n",
    "sets = {\n",
    "    \"kind_1\": kind_1,\n",
    "    \"kind_6\": kind_6,\n",
    "    \"kind_7\": kind_7\n",
    "}\n",
    "\n",
    "# Total number of unique pubkeys in the entire dataset\n",
    "all_pubkeys_count = events.select(pl.col(\"pubkey\").n_unique()).to_series().item()\n",
    "\n",
    "# Number of unique pubkeys involved in kinds 1, 6, and 7 combined\n",
    "all_kind_pubkeys_count = events.filter(pl.col(\"kind\").is_in([1, 6, 7])) \\\n",
    "    .select(pl.col(\"pubkey\").n_unique()).to_series().item()\n",
    "\n",
    "print(f\"Total unique pubkeys: {all_pubkeys_count}\")\n",
    "print(f\"Unique pubkeys in kinds 1, 6, 7: {all_kind_pubkeys_count} \"\n",
    "      f\"({all_kind_pubkeys_count / all_pubkeys_count * 100:.2f}%)\")\n",
    "\n",
    "# --- Step 2: Plot a proportional Venn diagram for the three sets ---\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# venn3 automatically sizes areas proportional to the set sizes and intersections\n",
    "venn3(subsets=sets.values(), set_labels=sets.keys())\n",
    "\n",
    "plt.title(\"Proportional Venn Diagram of Pubkeys by Event Kind 1, 6, 7\")\n",
    "plt.show()\n",
    "\n",
    "# --- Step 3: Compute and display intersections statistics ---\n",
    "\n",
    "intersections_df = compute_set_intersections(sets)\n",
    "print(intersections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540987e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 0: Compute CDFs of events and first pubkey appearances ---\n",
    "\n",
    "# CDF of total events by day\n",
    "daily = (\n",
    "    events\n",
    "    .group_by(\"day\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"day\")\n",
    ")\n",
    "\n",
    "total_events = daily[\"count\"].sum()\n",
    "\n",
    "cdf_df = daily.with_columns([\n",
    "    pl.col(\"count\").cum_sum().alias(\"cum_count\"),\n",
    "    (pl.col(\"count\").cum_sum() / total_events * 100).alias(\"cdf\")\n",
    "])\n",
    "\n",
    "# CDF of first appearance of each pubkey\n",
    "first_events = (\n",
    "    pubkey_stats\n",
    "    .select([\n",
    "        pl.col(\"pubkey\"),\n",
    "        pl.col(\"first_eventdate\")\n",
    "        .dt.date()\n",
    "        .alias(\"first_day\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "first_daily = (\n",
    "    first_events\n",
    "    .group_by(\"first_day\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"first_day\")\n",
    ")\n",
    "\n",
    "total_first = first_daily[\"count\"].sum()\n",
    "\n",
    "cdf_first_df = first_daily.with_columns([\n",
    "    pl.col(\"count\").cum_sum().alias(\"cum_count\"),\n",
    "    (pl.col(\"count\").cum_sum() / total_first * 100).alias(\"cdf\")\n",
    "])\n",
    "\n",
    "# --- Step 1: Calculate lifespan per pubkey (days) ---\n",
    "\n",
    "# Compute lifespan_days by converting lifespan_seconds to days\n",
    "pubkey_lifespan = pubkey_stats.with_columns([\n",
    "    (pl.col(\"lifespan\").cast(pl.Int64) / (1000 * 60 * 60 * 24)).alias(\"lifespan_days\")\n",
    "])\n",
    "# --- Step 2: Join lifespan info back to events ---\n",
    "\n",
    "events_lifespan = events.join(pubkey_lifespan.select([\"pubkey\", \"lifespan_days\"]), on=\"pubkey\", how=\"left\")\n",
    "\n",
    "# --- Step 3: Assign lifespan bucket to each event ---\n",
    "\n",
    "events_lifespan = events_lifespan.with_columns([\n",
    "    pl.when(pl.col(\"lifespan_days\") < 1)\n",
    "      .then(pl.lit(\"less_than_1_day\"))\n",
    "      .when((pl.col(\"lifespan_days\") >= 1) & (pl.col(\"lifespan_days\") <= 30))\n",
    "      .then(pl.lit(\"between_1_and_30_days\"))\n",
    "      .otherwise(pl.lit(\"more_than_30_days\"))\n",
    "      .alias(\"lifespan_bucket\")\n",
    "])\n",
    "\n",
    "# --- Step 4: Group by day and lifespan_bucket, count events ---\n",
    "\n",
    "daily_lifespan_counts = (\n",
    "    events_lifespan\n",
    "    .group_by([\"day\", \"lifespan_bucket\"])\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"day\")\n",
    ")\n",
    "\n",
    "# --- Step 5: Pivot so each lifespan bucket is a column for plotting stacked bars ---\n",
    "\n",
    "daily_pivot = daily_lifespan_counts.pivot(\n",
    "    values=\"count\",\n",
    "    index=\"day\",\n",
    "    columns=\"lifespan_bucket\",\n",
    "    aggregate_function=\"first\"\n",
    ").fill_null(0).sort(\"day\")\n",
    "\n",
    "# --- Step 6: Plot stacked bar chart along with CDFs ---\n",
    "\n",
    "days = pd.to_datetime(cdf_df[\"day\"].to_pandas())\n",
    "cdf_values = cdf_df[\"cdf\"].to_numpy()\n",
    "\n",
    "first_days = pd.to_datetime(cdf_first_df[\"first_day\"].to_pandas())\n",
    "cdf_first_values = cdf_first_df[\"cdf\"].to_numpy()\n",
    "\n",
    "hist_days = pd.to_datetime(daily_pivot[\"day\"].to_pandas())\n",
    "counts_less_1 = daily_pivot.get_column(\"less_than_1_day\").to_numpy() if \"less_than_1_day\" in daily_pivot.columns else np.zeros(len(daily_pivot))\n",
    "counts_1_to_30 = daily_pivot.get_column(\"between_1_and_30_days\").to_numpy() if \"between_1_and_30_days\" in daily_pivot.columns else np.zeros(len(daily_pivot))\n",
    "counts_more_30 = daily_pivot.get_column(\"more_than_30_days\").to_numpy() if \"more_than_30_days\" in daily_pivot.columns else np.zeros(len(daily_pivot))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Plot CDFs on primary y-axis\n",
    "ax.plot(days, cdf_values, drawstyle=\"steps-post\", label=\"CDF of total events\", color=\"tab:blue\")\n",
    "ax.plot(first_days, cdf_first_values, drawstyle=\"steps-post\", label=\"CDF of total pubkeys\", color=\"tab:green\")\n",
    "\n",
    "ax.set_xlabel(\"Date (Month-Year)\")\n",
    "ax.set_ylabel(\"CDF (%)\")\n",
    "ax.set_xlim(pd.to_datetime(\"2022-12-01\"), max(days.max(), first_days.max()))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.grid(True)\n",
    "\n",
    "# Secondary Y-axis: Stacked bar histogram of daily event counts by lifespan bucket\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(hist_days, counts_more_30, width=1.0, alpha=0.8, color=\"tab:green\", label=\"> 30 days lifespan\", linewidth=0)\n",
    "ax2.bar(hist_days, counts_1_to_30, bottom=counts_more_30, width=1.0, alpha=0.8, color=\"tab:orange\", label=\"1-30 days lifespan\", linewidth=0)\n",
    "ax2.bar(hist_days, counts_less_1, bottom=counts_more_30 + counts_1_to_30, width=1.0, alpha=0.8, color=\"tab:red\", label=\"< 1 day lifespan\", linewidth=0)\n",
    "\n",
    "ax2.set_ylabel(\"Number of Events (Daily)\")\n",
    "\n",
    "# Combined legend\n",
    "lines1, labels1 = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "plt.title(\"Daily CDFs + Stacked Daily Event Histogram by Pubkey Lifespan\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aggregate by month ---\n",
    "\n",
    "# Add a 'month' column to the daily table\n",
    "daily_pivot = daily_pivot.with_columns([\n",
    "    pl.col(\"day\").cast(pl.Date).dt.truncate(\"1mo\").alias(\"month\")\n",
    "])\n",
    "\n",
    "# Group by month and sum the counts\n",
    "monthly_pivot = (\n",
    "    daily_pivot\n",
    "    .group_by(\"month\")\n",
    "    .agg([\n",
    "        pl.col(\"less_than_1_day\").sum().alias(\"less_than_1_day\"),\n",
    "        pl.col(\"between_1_and_30_days\").sum().alias(\"between_1_and_30_days\"),\n",
    "        pl.col(\"more_than_30_days\").sum().alias(\"more_than_30_days\"),\n",
    "    ])\n",
    "    .sort(\"month\")\n",
    ")\n",
    "\n",
    "# --- Calculate monthly proportions ---\n",
    "\n",
    "months = pd.to_datetime(monthly_pivot[\"month\"].to_pandas())\n",
    "monthly_counts_less_1 = monthly_pivot[\"less_than_1_day\"].to_numpy()\n",
    "monthly_counts_1_to_30 = monthly_pivot[\"between_1_and_30_days\"].to_numpy()\n",
    "monthly_counts_more_30 = monthly_pivot[\"more_than_30_days\"].to_numpy()\n",
    "\n",
    "total_monthly = monthly_counts_less_1 + monthly_counts_1_to_30 + monthly_counts_more_30\n",
    "\n",
    "# Avoid division by zero\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    ratios_less_1 = np.nan_to_num(monthly_counts_less_1 / total_monthly)\n",
    "    ratios_1_to_30 = np.nan_to_num(monthly_counts_1_to_30 / total_monthly)\n",
    "    ratios_more_30 = np.nan_to_num(monthly_counts_more_30 / total_monthly)\n",
    "\n",
    "# --- Create DataFrame for the heatmap ---\n",
    "\n",
    "heatmap_data = pd.DataFrame({\n",
    "    \"month\": months,\n",
    "    \"< 1 day\": ratios_less_1,\n",
    "    \"1-30 days\": ratios_1_to_30,\n",
    "    \"> 30 days\": ratios_more_30,\n",
    "})\n",
    "\n",
    "# Set 'month' as index\n",
    "heatmap_data.set_index(\"month\", inplace=True)\n",
    "\n",
    "# Filter: include only months from 2022-12 onwards\n",
    "heatmap_data = heatmap_data[heatmap_data.index >= pd.to_datetime(\"2022-12-01\")]\n",
    "\n",
    "# Transpose to have categories as rows\n",
    "heatmap_data = heatmap_data.T\n",
    "\n",
    "# --- Plot heatmap ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"YlGnBu\",\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"white\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar_kws={'label': 'Proportion of Events'},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\"Monthly Heatmap of Event Proportions by Pubkey Lifespan\", fontsize=14)\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Pubkey Lifespan\")\n",
    "\n",
    "# --- Center x-tick labels under each heatmap cell ---\n",
    "xticks = np.arange(len(heatmap_data.columns)) + 0.5  # centers on cells\n",
    "xtick_labels = [dt.strftime(\"%Y-%m\") for dt in heatmap_data.columns]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xtick_labels, rotation=90, ha=\"center\")\n",
    "\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute DAU ---\n",
    "dau = (\n",
    "    events\n",
    "    .group_by(\"day\")\n",
    "    .agg(pl.col(\"pubkey\").n_unique().alias(\"DAU\"))\n",
    "    .sort(\"day\")\n",
    ")\n",
    "\n",
    "# Convert to pandas for rolling\n",
    "dau_pd = dau.to_pandas()\n",
    "dau_pd[\"day\"] = pd.to_datetime(dau_pd[\"day\"])\n",
    "dau_pd.set_index(\"day\", inplace=True)\n",
    "\n",
    "# --- Compute MAU using rolling window ---\n",
    "dau_pd[\"MAU\"] = dau_pd[\"DAU\"].rolling(\"30D\").sum()  # Overestimate, but close for simplicity\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "ax.plot(dau_pd.index, dau_pd[\"DAU\"], label=\"Daily Active Users\", color=\"tab:blue\")\n",
    "ax.plot(dau_pd.index, dau_pd[\"MAU\"], label=\"Monthly Active Users (Rolling Sum)\", color=\"tab:green\")\n",
    "\n",
    "ax.set_title(\"Daily and Monthly Active Users\")\n",
    "ax.set_xlabel(\"Date (Month-Year)\")\n",
    "ax.set_ylabel(\"Number of Unique Pubkeys\")\n",
    "ax.set_xlim(pd.to_datetime(\"2022-12-01\"), dau_pd.index.max())\n",
    "ax.set_yscale('log')\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.grid(True)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of kinds to keep\n",
    "subset_kinds = kind_stats.filter(\n",
    "    (pl.col(\"perc_event\") >= 1) | (pl.col(\"perc_pubkey\") >= 1)\n",
    ")[\"kind\"].to_list()\n",
    "\n",
    "# Create new column 'kind_group': keep kind if in subset, else -1\n",
    "events_grouped = events.with_columns([\n",
    "    pl.when(pl.col(\"kind\").is_in(subset_kinds))\n",
    "      .then(pl.col(\"kind\"))\n",
    "      .otherwise(-1)\n",
    "      .alias(\"kind_group\")\n",
    "])\n",
    "\n",
    "# Count events by month and kind_group\n",
    "counts = (\n",
    "    events_grouped\n",
    "    .group_by([\"month\", \"kind_group\"])\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort([\"month\", \"kind_group\"])\n",
    ")\n",
    "\n",
    "# Count total events per month\n",
    "totals = counts.group_by(\"month\").agg(pl.col(\"count\").sum().alias(\"total_count\"))\n",
    "\n",
    "# Join and calculate proportions\n",
    "joined = counts.join(totals, on=\"month\").with_columns(\n",
    "    (pl.col(\"count\") / pl.col(\"total_count\")).alias(\"proportion\")\n",
    ")\n",
    "\n",
    "# Pivot: kind_group as rows, months as columns\n",
    "pivot = joined.pivot(\n",
    "    values=\"proportion\",\n",
    "    index=\"kind_group\",\n",
    "    columns=\"month\"\n",
    ").fill_null(0).sort(\"kind_group\")\n",
    "\n",
    "# Filter months from 2022-12-01 onwards\n",
    "start_date = pd.Timestamp(\"2022-12-01\")\n",
    "months = [col for col in pivot.columns if col != \"kind_group\"]\n",
    "months_pd = [pd.to_datetime(str(m)) for m in months]\n",
    "filtered_cols = [\"kind_group\"] + [m for m, m_pd in zip(months, months_pd) if m_pd >= start_date]\n",
    "\n",
    "pivot = pivot.select(filtered_cols)\n",
    "\n",
    "# Convert to pandas for plotting\n",
    "df_heatmap = pivot.to_pandas().set_index(\"kind_group\")\n",
    "\n",
    "# Format month columns to YYYY-MM for nicer x-axis labels\n",
    "df_heatmap.columns = [pd.to_datetime(c).strftime(\"%Y-%m\") for c in df_heatmap.columns]\n",
    "\n",
    "# Sort rows by total sum descending\n",
    "df_heatmap = df_heatmap.loc[df_heatmap.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(20, 6))\n",
    "ax = sns.heatmap(\n",
    "    df_heatmap,\n",
    "    linewidths=0,\n",
    "    linecolor=\"white\",\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cbar_kws={\"label\": \"Proportion of Events\"}\n",
    ")\n",
    "\n",
    "ax.set_title(\"Monthly Proportion of Events by Kind\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_ylabel(\"Kind Group\")\n",
    "\n",
    "plt.xticks(rotation=90, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Convert to pandas\n",
    "df_area = pivot.to_pandas().set_index(\"kind_group\")\n",
    "\n",
    "# Sort rows (kind_group) by total share descending\n",
    "df_area = df_area.loc[df_area.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "# Extract months from columns as datetime\n",
    "months_str = df_area.columns.tolist()\n",
    "months_dt = [pd.to_datetime(m) for m in months_str]\n",
    "months_dt_sorted = sorted(months_dt)\n",
    "\n",
    "# Shift tick positions to the center of the step (middle of each month span)\n",
    "months_dt_shifted = [m + pd.Timedelta(days=15) for m in months_dt_sorted]\n",
    "\n",
    "# Extend months for step='post'\n",
    "months_extended = months_dt_sorted + [months_dt_sorted[-1] + relativedelta(months=1)]\n",
    "\n",
    "# Extract kind_group values\n",
    "kind_groups = df_area.index.tolist()\n",
    "\n",
    "# Prepare data matrix\n",
    "stack_data = df_area[months_str].values\n",
    "last_col = stack_data[:, -1][:, np.newaxis]\n",
    "stack_data_extended = np.hstack([stack_data, last_col])\n",
    "\n",
    "# Colors\n",
    "num_kinds = len(kind_groups)\n",
    "cmap = cm.get_cmap(\"tab20\", num_kinds)\n",
    "colors = [cmap(i) for i in range(num_kinds)]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.stackplot(\n",
    "    months_extended,\n",
    "    stack_data_extended,\n",
    "    labels=[str(k) for k in kind_groups],\n",
    "    colors=colors,\n",
    "    step='post',\n",
    "    linewidths=0\n",
    ")\n",
    "\n",
    "# Labels and axes\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "ax.set_title(\"Monthly Proportion of Events by Kind\")\n",
    "ax.set_xlim([months_extended[0], months_extended[-1]])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"Month\")\n",
    "\n",
    "# Center ticks between steps\n",
    "ax.set_xticks(months_dt_shifted)\n",
    "ax.set_xticklabels([d.strftime(\"%Y-%m\") for d in months_dt_sorted], rotation=90, ha=\"center\")\n",
    "\n",
    "# Legend\n",
    "ax.legend(title=\"Kind Group\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e998fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifespan_data = pubkey_stats.with_columns([\n",
    "    (pl.col(\"lifespan\").cast(pl.Float64) / 1000).alias(\"lifespan_scaled\")\n",
    "])\n",
    "\n",
    "lifespan_sorted = np.sort(lifespan_data[\"lifespan_scaled\"].to_numpy())\n",
    "cdf = np.arange(1, len(lifespan_sorted) + 1) / len(lifespan_sorted)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(lifespan_sorted, cdf, label=\"CDF\", color=\"tab:blue\")\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "ticks_values = [1, 60, 3600, 86400, 604800, 2592000, 31536000]\n",
    "ticks_labels = [\"1 sec\", \"1 min\", \"1 hr\", \"1 day\", \"1 wk\", \"1 mo\", \"1 yr\"]\n",
    "\n",
    "ax.set_xticks(ticks_values)\n",
    "ax.set_xticklabels(ticks_labels)\n",
    "\n",
    "ax.set_xlabel(\"Lifespan\")\n",
    "ax.set_ylabel(\"CDF\")\n",
    "ax.set_title(\"CDF of Pubkey Lifespan\")\n",
    "ax.grid(True)\n",
    "ax.set_ylim(0.79, 1.01)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filtro per chiavi con più di 2 eventi e primo evento dopo il 2022-12-01\n",
    "df = pubkey_stats.filter(\n",
    "    (pl.col(\"event_count\") > 2) &\n",
    "    (pl.col(\"first_eventdate\") > pl.datetime(2022, 12, 1))\n",
    ")\n",
    "\n",
    "# Aggiungi colonne timestamp in secondi (Int64)\n",
    "df = df.with_columns([\n",
    "    (pl.col(\"first_eventdate\").cast(pl.Int64) // 1_000).alias(\"first_eventdate_sec\"),\n",
    "    (pl.col(\"last_eventdate\").cast(pl.Int64) // 1_000).alias(\"last_eventdate_sec\"),\n",
    "])\n",
    "\n",
    "# Converte le colonne duration in secondi (Int64)\n",
    "for col in [\"lifespan\", \"mean_interval\", \"median_interval\", \"std_interval\"]:\n",
    "    df = df.with_columns(\n",
    "        (pl.col(col).cast(pl.Int64) // 1_000).alias(f\"{col}_sec\")\n",
    "    )\n",
    "\n",
    "# Seleziona solo le feature per il clustering\n",
    "features = df.select([\n",
    "    \"event_count\",\n",
    "    \"first_eventdate_sec\",\n",
    "    \"last_eventdate_sec\",\n",
    "    \"lifespan_sec\",\n",
    "    \"mean_interval_sec\",\n",
    "    \"median_interval_sec\",\n",
    "    \"std_interval_sec\"\n",
    "]).to_pandas()\n",
    "\n",
    "# Normalizzazione\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Clustering con KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Aggiungi cluster al DataFrame Polars\n",
    "df = df.with_columns(pl.Series(name=\"cluster\", values=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ed114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas\n",
    "df_pd = df.to_pandas()\n",
    "\n",
    "# Readable mapping: feature → (label, column, type)\n",
    "feature_info = {\n",
    "    \"event_count\": (\"Pubkey Event Count\", \"event_count\", \"numeric\"),\n",
    "    \"first_eventdate\": (\"Pubkey First Event\", \"first_eventdate\", \"datetime\"),\n",
    "    \"last_eventdate\": (\"Pubkey Last Event\", \"last_eventdate\", \"datetime\"),\n",
    "    \"lifespan\": (\"Pubkey Lifespan\", \"lifespan\", \"duration\"),\n",
    "    \"mean_interval\": (\"Pubkey Mean Interval\", \"mean_interval\", \"duration\"),\n",
    "    \"median_interval\": (\"Pubkey Median Interval\", \"median_interval\", \"duration\"),\n",
    "    \"std_interval\": (\"Pubkey Std. Interval\", \"std_interval\", \"duration\"),\n",
    "}\n",
    "\n",
    "# Palette for clusters\n",
    "palette = sns.color_palette(\"Set2\", n_colors=df_pd[\"cluster\"].nunique())\n",
    "\n",
    "# Fixed ticks in seconds and their corresponding labels for duration axis\n",
    "fixed_ticks = [\n",
    "    1,          # 1 second\n",
    "    60,         # 1 minute\n",
    "    3600,       # 1 hour\n",
    "    86400,      # 1 day\n",
    "    604800,     # 1 week\n",
    "    2592000,    # 1 month (approx. 30 days)\n",
    "    31536000,   # 1 year\n",
    "]\n",
    "fixed_labels = [\"1 sec\", \"1 min\", \"1 hr\", \"1 day\", \"1 wk\", \"1 mo\", \"1 yr\"]\n",
    "\n",
    "def fixed_duration_formatter(x, pos):\n",
    "    # Return label only if x matches a fixed tick, else empty string\n",
    "    if x in fixed_ticks:\n",
    "        idx = fixed_ticks.index(x)\n",
    "        return fixed_labels[idx]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Pre-conversion: datetime and duration → seconds as float\n",
    "for key, (_, col, kind) in feature_info.items():\n",
    "    if kind == \"datetime\":\n",
    "        df_pd[col + \"_sec\"] = df_pd[col].astype(\"int64\") // 1_000\n",
    "    elif kind == \"duration\":\n",
    "        df_pd[col + \"_sec\"] = df_pd[col].dt.total_seconds()\n",
    "\n",
    "# Plotting\n",
    "for key, (label, col, kind) in feature_info.items():\n",
    "    plot_col = col + \"_sec\" if kind in {\"datetime\", \"duration\"} else col\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.boxplot(\n",
    "        x=\"cluster\",\n",
    "        y=plot_col,\n",
    "        data=df_pd,\n",
    "        palette=palette,\n",
    "        showfliers=True,\n",
    "        linewidth=1\n",
    "    )\n",
    "\n",
    "    # Overlay mean (red diamond) and median (blue circle)\n",
    "    means = df_pd.groupby(\"cluster\")[plot_col].mean()\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        ax.plot(i, means[i], marker='D', color='red', markersize=6, label='Mean' if i == 0 else \"\")\n",
    "\n",
    "    plt.title(f\"{label} by Cluster\", fontsize=14)\n",
    "    plt.xlabel(\"Cluster\", fontsize=12)\n",
    "    plt.ylabel(label, fontsize=12)\n",
    "\n",
    "    # Custom y-axis formatting\n",
    "    if kind == \"duration\":\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.yaxis.set_major_locator(mticker.FixedLocator(fixed_ticks))\n",
    "        ax.yaxis.set_major_formatter(mticker.FuncFormatter(fixed_duration_formatter))\n",
    "    elif kind == \"numeric\":\n",
    "        ax.set_yscale(\"log\")\n",
    "    elif kind == \"datetime\":\n",
    "        ax.yaxis.set_major_formatter(\n",
    "            plt.FuncFormatter(lambda x, _: datetime.datetime.fromtimestamp(x).strftime(\"%Y-%m\"))\n",
    "        )\n",
    "\n",
    "    plt.grid(True)\n",
    "    if 'Mean' in ax.get_legend_handles_labels()[1]:\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc2589",
   "metadata": {},
   "source": [
    "- pubkey followers: cdf del numero di followers per pubkey\n",
    "- correlazione tra eventi pubblicati e follower per pubkey. vedere quali e quante pubkey hanno tanti followers e pubblicano tanto (ele altre tre possibilita')\n",
    "- pubkey nei relays\n",
    "- event resilience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigbrotr.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
